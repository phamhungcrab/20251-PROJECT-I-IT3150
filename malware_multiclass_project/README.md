# Malware Multiclass Classification (Windows PE) — Colab-ready

Dự án này được thiết kế để:
- Đọc 4 feature sets (DLLs, APIs, PE Header, PE Section)
- Align theo `sha256` (intersection) để tránh mismatch
- Build `X` dạng **sparse CSR** (tối ưu RAM)
- Split **train/val/test stratified** (KHÔNG leakage)
- Train mô hình:
  - Logistic Regression (ElasticNet) — baseline mạnh cho sparse high-dim
  - LightGBM (tuỳ chọn) — thường cho accuracy cao hơn
- In/log rất nhiều thông tin để debug + tối ưu

## 1) Cấu trúc thư mục đề xuất

```
/content/drive/MyDrive/malware/
  DLLs_Imported.csv
  API_Functions.csv
  PE_Header.csv
  PE_Section.csv

  cache/                     # parquet cache tự tạo (tuỳ chọn)
  processed/                 # sparse dataset cache tự tạo (X_all.npz, y_all.npy, ...)
  outputs/
    logs/
    models/
    reports/
```

## 2) Chạy trên Google Colab

Trong Colab:

```python
from google.colab import drive
drive.mount('/content/drive')
```

(Optional) cài LightGBM + Optuna:

```bash
pip -q install lightgbm optuna
```

Chạy train:

```bash
python run_colab.py
```

## 3) Anti-leakage

- Split dựa trên `y` (stratify) và index sample.
- Có check **sha256 overlap** giữa train/val/test → nếu overlap thì assert fail.
- Tuning chỉ dùng validation, test giữ nguyên đến cuối.

## 4) Output

- `outputs/models/model_<name>_<run_id>.joblib`
- `outputs/reports/metrics_<name>_<run_id>.json`
- `outputs/logs/train_<run_id>.log`
- Explainability:
  - Logistic: `top_features_logreg_<run_id>.json`
  - LightGBM: `feature_importance_lgbm_<run_id>.json`
